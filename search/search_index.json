{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documentation DWH ShopNow \u2013 Terraform &amp; DBT","text":"<p>Bienvenue dans la documentation du Data Warehouse ShopNow. Cette documentation couvre la configuration, le mod\u00e8le de donn\u00e9es, les pipelines DBT et l'infrastructure Terraform utilis\u00e9e pour supporter le DWH Marketplace.</p>"},{"location":"#objectifs-de-la-documentation","title":"Objectifs de la documentation","text":"<ul> <li>D\u00e9crire la structure et le fonctionnement du DWH</li> <li>Documenter le projet DBT pour la transformation et la qualit\u00e9 des donn\u00e9es</li> <li>D\u00e9crire l\u2019infrastructure Terraform pour d\u00e9ploiement et gestion des ressources</li> <li>Fournir des r\u00e9f\u00e9rences sur les r\u00f4les, permissions et bonnes pratiques</li> <li>Centraliser toutes les informations pour les \u00e9quipes data et devops</li> </ul>"},{"location":"#navigation-rapide","title":"Navigation rapide","text":""},{"location":"#base-de-donnees","title":"Base de donn\u00e9es","text":"<ul> <li>Pr\u00e9sentation du mod\u00e8le de donn\u00e9es</li> <li>Sch\u00e9ma des dimensions et tables de faits</li> <li>R\u00f4les et permissions SQL</li> </ul>"},{"location":"#dbt-data-build-tool","title":"DBT (Data Build Tool)","text":"<ul> <li>Structure du projet DBT (<code>staging</code> &amp; <code>marts</code>)</li> <li>Sources, mod\u00e8les et transformations</li> <li>Tests de qualit\u00e9 (not_null, unique, relationships)</li> </ul>"},{"location":"#terraform","title":"Terraform","text":"<ul> <li>D\u00e9ploiement de l\u2019infrastructure Azure</li> <li>Modules : containers, Event Hubs, Stream Analytics, SQL Database</li> <li>Variables et providers</li> </ul>"},{"location":"database/","title":"Base de donn\u00e9es \u2013 Data Warehouse ShopNow","text":""},{"location":"database/#1-introduction","title":"1. Introduction","text":"<p>Ce document pr\u00e9sente la structure du Data Warehouse (DWH) de ShopNow, adapt\u00e9 au mod\u00e8le Marketplace. Il inclut :</p> <ul> <li>Les dimensions et faits</li> <li>Les relations entre tables</li> <li>Les r\u00f4les et permissions pour les utilisateurs</li> </ul>"},{"location":"database/#2-dimensions","title":"2. Dimensions","text":""},{"location":"database/#dim_customer","title":"dim_customer","text":"<p>Repr\u00e9sente les clients de ShopNow.</p> Colonne Type Description customer_sk INT PK Cl\u00e9 sur la table customer_id VARCHAR(50) Identifiant unique du client name NVARCHAR(255) Nom du client email NVARCHAR(255) Email du client city NVARCHAR(100) Ville country NVARCHAR(100) Pays address NVARCHAR(500) Adresse start_date DATE Date de d\u00e9but de validit\u00e9 end_date DATE Date de fin de validit\u00e9 is_current BIT Indique si l\u2019enregistrement est actif"},{"location":"database/#dim_seller","title":"dim_seller","text":"<p>Repr\u00e9sente les vendeurs Marketplace.</p> Colonne Type Description seller_sk INT PK Cl\u00e9 sur la table seller_id VARCHAR(50) Identifiant unique du vendeur name NVARCHAR(255) Nom du vendeur status NVARCHAR(50) Statut du vendeur country NVARCHAR(100) Pays city NVARCHAR(100) Ville address NVARCHAR(500) Adresse start_date DATE Date de d\u00e9but end_date DATE Date de fin is_current BIT Actif ou non"},{"location":"database/#dim_product","title":"dim_product","text":"<p>Repr\u00e9sente les produits vendus sur la plateforme.</p> Colonne Type Description product_sk INT PK Cl\u00e9 sur la table product_id VARCHAR(50) Identifiant unique du produit name NVARCHAR(255) Nom du produit category NVARCHAR(100) Cat\u00e9gorie description NVARCHAR(MAX) Description du produit start_date DATE Date de d\u00e9but end_date DATE Date de fin is_current BIT Actif ou non"},{"location":"database/#dim_seller_product_pricing","title":"dim_seller_product_pricing","text":"<p>Associe les vendeurs aux produits et leurs prix.</p> Colonne Type Description seller_product_sk INT PK Cl\u00e9 primaire seller_sk INT FK R\u00e9f\u00e9rence <code>dim_seller</code> product_sk INT FK R\u00e9f\u00e9rence <code>dim_product</code> price DECIMAL(18,2) Prix du produit start_date DATE Date de d\u00e9but end_date DATE Date de fin is_current BIT Actif ou non"},{"location":"database/#3-tables-de-faits","title":"3. Tables de faits","text":""},{"location":"database/#fact_order","title":"fact_order","text":"<p>Repr\u00e9sente les commandes des clients.</p> Colonne Type Description order_id VARCHAR(50) PK Identifiant de la commande customer_sk INT FK R\u00e9f\u00e9rence <code>dim_customer</code> order_date DATE Date de la commande total_amount DECIMAL(18,2) Montant total"},{"location":"database/#fact_order_items","title":"fact_order_items","text":"<p>D\u00e9tails des produits command\u00e9s par commande.</p> Colonne Type Description order_id VARCHAR(50) FK R\u00e9f\u00e9rence <code>fact_order</code> seller_product_sk INT FK R\u00e9f\u00e9rence <code>dim_seller_product_pricing</code> quantity INT Quantit\u00e9 command\u00e9e"},{"location":"database/#fact_seller_product_stock","title":"fact_seller_product_stock","text":"<p>Historique des stocks par produit et vendeur.</p> Colonne Type Description seller_product_sk INT PK,FK R\u00e9f\u00e9rence <code>dim_seller_product_pricing</code> event_timestamp DATETIME PK Date/heure de l\u2019\u00e9v\u00e9nement stock INT Quantit\u00e9 en stock source NVARCHAR(100) Source de l\u2019information"},{"location":"database/#fact_clickstream","title":"fact_clickstream","text":"<p>\u00c9v\u00e9nements de navigation des utilisateurs.</p> Colonne Type Description event_id VARCHAR(50) PK Identifiant unique session_id VARCHAR(50) Identifiant de session user_id VARCHAR(50) Identifiant de l\u2019utilisateur url NVARCHAR(MAX) Page visit\u00e9e event_type NVARCHAR(50) Type d\u2019\u00e9v\u00e9nement event_timestamp DATETIME Date/heure de l\u2019\u00e9v\u00e9nement"},{"location":"database/#4-relations-entre-tables","title":"4. Relations entre tables","text":""},{"location":"database/#avant","title":"Avant","text":"<pre><code>erDiagram\n\n    %% =======================\n    %% DIMENSIONS\n    %% =======================\n\n    dim_customer {\n        string customer_id\n        string name\n        string email\n        string city\n        string country\n        string address\n    }\n\n    dim_product {\n        string product_id\n        string name\n        string category\n    }\n\n    %% =======================\n    %% FACTS\n    %% =======================\n\n    fact_order {\n        string order_id\n        string product_id\n        string customer_id\n        int quantity        \n        float unit_price\n        string status\n        date order_timestamp\n    }\n\n\n    fact_clickstream {\n        string event_id PK\n        string session_id \n        string user_id    \n        string url        \n        string event_type \n        date   event_timestamp \n    }\n\n    %% =======================\n    %% RELATIONS\n    %% =======================\n\n    dim_customer ||--o{ fact_order : customer_id\n    dim_product ||--o{ fact_order : product_id\n</code></pre>"},{"location":"database/#proposition-nouveau-schema","title":"Proposition nouveau schema","text":"<pre><code>erDiagram\n\n    %% =======================\n    %% DIMENSIONS\n    %% =======================\n\n    dim_customer {\n        int    customer_sk PK\n        string customer_id\n        string name\n        string email\n        string city\n        string country\n        string address\n        date   start_date\n        date   end_date\n        boolean is_current\n    }\n\n    dim_seller {\n        int    seller_sk PK\n        string seller_id \n        string name\n        string status\n        string country\n        string city\n        string address\n        date   start_date\n        date   end_date\n        boolean is_current\n    }\n\n    dim_product {\n        int    product_sk PK\n        string product_id\n        string name\n        string category\n        string description\n        date   start_date\n        date   end_date\n        boolean is_current\n    }\n\n    dim_seller_product_pricing {\n        int    seller_product_sk PK\n        int    seller_sk FK\n        int    product_sk FK\n        float  price\n        date   start_date\n        date   end_date\n        boolean is_current\n    }\n\n    %% =======================\n    %% FACTS\n    %% =======================\n\n    fact_order {\n        string order_id PK\n        int    customer_sk FK\n        date    order_date\n        float  total_amount\n    }\n\n    fact_order_items {\n        string order_id FK\n        int    seller_product_sk FK\n        int    quantity\n    }\n\n    fact_seller_product_stock {\n        date   event_timestamp PK\n        int    seller_product_sk PK,FK\n        int    stock\n        string source\n    }\n\n    fact_clickstream {\n        string event_id PK\n        string session_id \n        string user_id    \n        string url        \n        string event_type \n        date   event_timestamp \n    }\n\n    %% =======================\n    %% RELATIONS\n    %% =======================\n\n    dim_customer ||--o{ fact_order : customer_sk\n\n    fact_order ||--o{ fact_order_items : order_id\n\n    dim_seller ||--o{ dim_seller_product_pricing : seller_sk\n    dim_product ||--o{ dim_seller_product_pricing : product_sk\n\n    dim_seller_product_pricing ||--o{ fact_order_items : seller_product_sk\n    dim_seller_product_pricing ||--o{ fact_seller_product_stock : seller_product_sk</code></pre>"},{"location":"database/#5-roles-et-permissions","title":"5. R\u00f4les et permissions","text":"R\u00f4le Description Permissions principales role_data_engineer Gestion ETL, sch\u00e9mas, tables, dbt CRUD sur sch\u00e9mas, contr\u00f4le complet role_system_admin Infrastructure, monitoring, backups Lecture globale, ALTER, BACKUP role_quality_operator Contr\u00f4le qualit\u00e9, validation des donn\u00e9es Lecture, cr\u00e9ation objets qualit\u00e9 role_data_governance Documentation, conformit\u00e9 RGPD, gestion acc\u00e8s Lecture compl\u00e8te, cr\u00e9ation vues, gestion utilisateurs role_read_only Analystes, BI Lecture seule sur marts"},{"location":"database/#6-schemas-supplementaires","title":"6. Sch\u00e9mas suppl\u00e9mentaires","text":"<ul> <li> <p>staging : tables  pour transformations interm\u00e9diaires</p> </li> <li> <p>marts : tables destin\u00e9es aux analyses et reporting</p> </li> </ul>"},{"location":"events_producers/","title":"Producteur d\u2019\u00e9v\u00e9nements \u2013 <code>_events_producers</code>","text":"<p>Le script <code>producers.py</code> permet de simuler et envoyer des flux de donn\u00e9es vers Azure Event Hubs pour le DWH ShopNow. Il produit des \u00e9v\u00e9nements pour les commandes, stocks et clickstreams, en utilisant des donn\u00e9es r\u00e9alistes g\u00e9n\u00e9r\u00e9es avec <code>Faker</code> et les tables du DWH.</p>"},{"location":"events_producers/#1-structure-du-dossier","title":"1. Structure du dossier","text":"<pre><code>_events_producers/\n\u251c\u2500\u2500 Dockerfile # Conteneurisation du producer\n\u251c\u2500\u2500 producers.py # Script principal\n\u251c\u2500\u2500 README.md # Cette documentation\n\u2514\u2500\u2500 requirements.txt # Librairies Python (faker, sqlalchemy, azure-eventhub...)\n</code></pre>"},{"location":"events_producers/#2-variables-denvironnement","title":"2. Variables d\u2019environnement","text":"<p>Le script utilise dotenv pour charger les param\u00e8tres de connexion et les intervalles d\u2019\u00e9v\u00e9nements.  </p> <pre><code># Connexion \u00e0 la base SQL\nSQL_USER=\"\"\nSQL_PASSWORD=\"\"\nSQL_SERVER=\"\"\nSQL_DB=\"dwh-shopnow\"\n\n# Connexion \u00e0 Azure Event Hubs\nEVENTHUB_CONN_STR=\"\"\n\n# Intervalles en secondes pour la g\u00e9n\u00e9ration d'\u00e9v\u00e9nements\nORDERS_INTERVAL=30        # Commandes\nSTOCK_INTERVAL=30         # Stocks\nCLICKSTREAM_INTERVAL=3    # Clickstreams\n</code></pre> <p>Conseil : ne pas commiter ce fichier sur un repo public, car il contient des credentials sensibles.</p>"},{"location":"events_producers/#3-connexion-et-chargement-des-donnees","title":"3. Connexion et chargement des donn\u00e9es","text":"<p>Le script utilise SQLAlchemy pour r\u00e9cup\u00e9rer les donn\u00e9es existantes et remplir les pools :</p> <p>| Pool  |Table SQL| |Description| |---------------|-------------|---------------------------------| |CUSTOMERS_POOL |dim_customer   |Clients existants| |SELLERS_POOL   |dim_seller |Vendeurs existants| |PRODUCTS_POOL  |dim_product    |Produits existants| |SELLER_PRODUCT_POOL    |dim_seller_product_pricing |Produits avec vendeurs et prix|</p> <p>Ces pools sont utilis\u00e9s pour g\u00e9n\u00e9rer des \u00e9v\u00e9nements r\u00e9alistes.</p>"},{"location":"events_producers/#4-types-devenements","title":"4. Types d\u2019\u00e9v\u00e9nements","text":""},{"location":"events_producers/#a-commandes-build_order_event","title":"a. Commandes (build_order_event)","text":"<p>S\u00e9lection al\u00e9atoire d\u2019un client</p> <p>S\u00e9lection de 1 \u00e0 5 produits vendus par diff\u00e9rents vendeurs</p> <p>Calcul du total_amount et construction des items <pre><code>{\n  \"event_type\": \"order\",\n  \"event_id\": \"uuid\",\n  \"order_id\": \"uuid\",\n  \"customer_sk\": 1,\n  \"items\": [\n    {\"seller_product_sk\": 5, \"quantity\": 2, \"unit_price\": 50.0}\n  ],\n  \"total_amount\": 100.0,\n  \"currency\": \"USD\",\n  \"status\": \"PLACED\",\n  \"timestamp\": \"2026-02-11T12:00:00Z\"\n}\n</code></pre></p>"},{"location":"events_producers/#b-stock-build_stock_event","title":"b. Stock (build_stock_event)","text":"<p>S\u00e9lection al\u00e9atoire d\u2019un produit-vendeur</p> <p>G\u00e9n\u00e8re la quantit\u00e9 disponible <pre><code>{\n  \"event_id\": \"uuid\",\n  \"seller_product_sk\": 5,\n  \"stock\": 120,\n  \"event_timestamp\": \"2026-02-11T12:00:00Z\",\n  \"source\": \"generator\"\n}\n</code></pre></p>"},{"location":"events_producers/#c-clickstream-build_clickstream_event","title":"c. Clickstream (build_clickstream_event)","text":"<p>Simule des actions utilisateur : view_page, add_to_cart, checkout_start</p> <p>G\u00e9n\u00e8re un user_agent et ip avec Faker</p> <pre><code>{\n  \"event_type\": \"clickstream\",\n  \"event_id\": \"uuid\",\n  \"session_id\": \"uuid\",\n  \"user_id\": \"uuid\",\n  \"url\": \"/product/abc123\",\n  \"action\": \"view_page\",\n  \"user_agent\": \"Mozilla/5.0 ...\",\n  \"ip\": \"192.168.1.1\",\n  \"timestamp\": \"2026-02-11T12:00:00Z\"\n}\n</code></pre>"},{"location":"events_producers/#5-envoi-vers-event-hubs","title":"5. Envoi vers Event Hubs","text":"<pre><code>def send_event(hub_name, event):\n    batch = producers[hub_name].create_batch()\n    batch.add(EventData(json.dumps(event)))\n    producers[hub_name].send_batch(batch)\n</code></pre> <ul> <li> <p>S\u00e9rialise l\u2019\u00e9v\u00e9nement en JSON</p> </li> <li> <p>Envoie dans le hub correspondant (orders, stock, clickstream)</p> </li> <li> <p>Affiche dans la console les \u00e9v\u00e9nements envoy\u00e9s</p> </li> </ul>"},{"location":"events_producers/#6-boucle-principale","title":"6. Boucle principale","text":"<p>V\u00e9rifie chaque intervalle configur\u00e9 (ORDERS_INTERVAL, STOCK_INTERVAL, CLICKSTREAM_INTERVAL)</p> <p>Envoie les \u00e9v\u00e9nements correspondants</p> <p>Pause de 0,5 seconde pour limiter la charge CPU</p> <p>Affiche les logs pour suivre l\u2019envoi <pre><code>while True:\n    now = time.time()\n    for name, interval in EVENT_HUBS.items():\n        if now - timers[name] &gt;= interval:\n            if name==\"orders\":\n                send_event(name, build_order_event())\n            elif name==\"stock\":\n                send_event(name, build_stock_event())\n            elif name==\"clickstream\":\n                send_event(name, build_clickstream_event())\n            timers[name] = now\n    time.sleep(0.5)\n</code></pre></p>"},{"location":"events_producers/#7-installation-et-execution","title":"7. Installation et ex\u00e9cution","text":""},{"location":"events_producers/#a-installer-les-dependances","title":"a. Installer les d\u00e9pendances","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"events_producers/#b-lancer-le-producteur","title":"b. Lancer le producteur","text":"<pre><code>python producers.py\n</code></pre>"},{"location":"shopnow_dbt/","title":"Projet DBT \u2013 ShopNow","text":""},{"location":"shopnow_dbt/#1-introduction","title":"1. Introduction","text":"<p>Ce dossier contient le projet DBT (Data Build Tool) pour transformer les donn\u00e9es brutes du DWH ShopNow en mod\u00e8les analytiques pr\u00eats pour le reporting. L\u2019objectif est de structurer, nettoyer et historiser les donn\u00e9es pour supporter le mod\u00e8le Marketplace multi-vendeurs.</p>"},{"location":"shopnow_dbt/#2-configuration-generale-dbt_projectyml","title":"2. Configuration g\u00e9n\u00e9rale (<code>dbt_project.yml</code>)","text":"<ul> <li>Nom du projet : <code>shopnow_dbt</code></li> <li>Version : <code>1.0.0</code></li> <li>Profil DBT : <code>shopnow_dbt</code></li> <li>R\u00e9pertoires utilis\u00e9s :</li> <li><code>models/</code> : mod\u00e8les de transformation</li> <li><code>analyses/</code> : analyses ad hoc</li> <li><code>tests/</code> : tests de qualit\u00e9 des donn\u00e9es</li> <li><code>seeds/</code> : tables statiques</li> <li><code>macros/</code> : fonctions SQL r\u00e9utilisables</li> <li><code>snapshots/</code> : historique des donn\u00e9es</li> <li>Mod\u00e8les <code>staging</code> et <code>marts</code> sont mat\u00e9rialis\u00e9s sous forme de tables et organis\u00e9s par sch\u00e9ma (<code>staging</code> / <code>marts</code>).</li> </ul>"},{"location":"shopnow_dbt/#3-sources-modelsstagingsrcyml","title":"3. Sources (<code>models/staging/src.yml</code>)","text":"<p>Les tables brutes proviennent du DWH ShopNow (<code>database=dwh-shopnow</code>, <code>schema=dbo</code>) :</p> Table source Description dim_customer Dimension client brute dim_seller Dimension vendeur brute dim_product Dimension produit brute dim_seller_product_pricing Tarification produits-vendeurs brute fact_order Faits commandes brute fact_order_items D\u00e9tails des commandes brute fact_seller_product_stock \u00c9v\u00e9nements stock brute fact_clickstream \u00c9v\u00e9nements de navigation utilisateur"},{"location":"shopnow_dbt/#4-modeles-de-staging","title":"4. Mod\u00e8les de staging","text":"<p>Les mod\u00e8les <code>stg_</code> permettent de nettoyer et normaliser les donn\u00e9es brutes avant de les int\u00e9grer dans les marts analytiques.</p>"},{"location":"shopnow_dbt/#exemple-de-transformation","title":"Exemple de transformation :","text":"<p>stg_customer.sql <pre><code>SELECT\n    customer_sk,\n    customer_id,\n    TRIM(name) AS customer_name,\n    LOWER(email) AS email,\n    city,\n    country,\n    address,\n    start_date,\n    end_date,\n    is_current\nFROM {{ source('shopnow_raw', 'dim_customer') }}\nWHERE customer_id IS NOT NULL\n</code></pre></p>"},{"location":"shopnow_dbt/#5-modeles-de-marts","title":"5. Mod\u00e8les de Marts","text":"<p>Les mod\u00e8les Marts repr\u00e9sentent les tables finales destin\u00e9es aux analyses et au reporting. Elles sont construites \u00e0 partir des staging models et incluent des agr\u00e9gations et KPIs. Chaque table est test\u00e9e pour garantir l\u2019int\u00e9grit\u00e9 des donn\u00e9es.</p>"},{"location":"shopnow_dbt/#exemple-de-table","title":"Exemple de table :","text":"<pre><code>SELECT *\nFROM {{ ref('stg_customer') }}\nWHERE is_current = 1\n</code></pre>"},{"location":"shopnow_dbt/#6-tests-de-qualite","title":"6. Tests de qualit\u00e9","text":""},{"location":"shopnow_dbt/#a-tests-sur-les-modeles-de-staging","title":"a. Tests sur les mod\u00e8les de staging","text":"Mod\u00e8le Colonne Test DBT Objectif stg_customer customer_sk not_null, unique Assurer qu\u2019il n\u2019y a pas de doublons ni de valeurs nulles stg_customer customer_id not_null, unique Cl\u00e9 externe fiable pour les relations stg_customer email not_null V\u00e9rifier que les emails existent stg_seller seller_sk not_null, unique Cl\u00e9 primaire unique stg_seller seller_id not_null, unique Identifiant vendeur unique stg_product product_sk not_null, unique Cl\u00e9 primaire unique stg_order order_id not_null, unique Identifier chaque commande de mani\u00e8re unique stg_order customer_sk not_null, relationships \u2192 stg_customer.customer_sk Assurer l'int\u00e9grit\u00e9 des relations client stg_order_items order_id not_null, relationships \u2192 stg_order.order_id Lier les items \u00e0 une commande existante stg_order_items seller_product_sk relationships \u2192 stg_seller_product_pricing.seller_product_sk Lier les items aux produits vendus"},{"location":"shopnow_dbt/#b-tests-sur-les-modeles-marts","title":"b. Tests sur les mod\u00e8les Marts","text":"Mod\u00e8le Colonne Test DBT Objectif dim_customer customer_sk not_null, unique Cl\u00e9 primaire, pas de doublons dim_seller seller_sk not_null, unique Cl\u00e9 primaire dim_product product_sk not_null, unique Cl\u00e9 primaire fact_sales order_id not_null Chaque ligne correspond \u00e0 une commande fact_sales customer_sk relationships \u2192 dim_customer.customer_sk Int\u00e9grit\u00e9 relationnelle avec client fact_sales product_sk relationships \u2192 dim_product.product_sk Int\u00e9grit\u00e9 relationnelle avec produit fact_sales seller_sk relationships \u2192 dim_seller.seller_sk Int\u00e9grit\u00e9 relationnelle avec vendeur"},{"location":"shopnow_dbt/#7-structure-des-modeles-dbt","title":"7. Structure des mod\u00e8les DBT","text":"<pre><code>shopnow_dbt/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 staging/                # Tables de staging (nettoyage, standardisation)\n\u2502   \u2502   \u251c\u2500\u2500 src.yml\n\u2502   \u2502   \u251c\u2500\u2500 schema.yml\n\u2502   \u2502   \u251c\u2500\u2500 stg_customer.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_seller.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_product.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_seller_product_pricing.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_order.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_order_items.sql\n\u2502   \u2502   \u251c\u2500\u2500 stg_stock.sql\n\u2502   \u2502   \u2514\u2500\u2500 stg_clickstream.sql\n\u2502   \u2514\u2500\u2500 marts/                  # Mod\u00e8les analytiques (agr\u00e9gations, KPIs)\n\u2502       \u251c\u2500\u2500 dim_customer.sql\n\u2502       \u251c\u2500\u2500 dim_product.sql\n\u2502       \u251c\u2500\u2500 dim_seller.sql\n\u2502       \u251c\u2500\u2500 fact_clickstream.sql\n\u2502       \u251c\u2500\u2500 fact_sales.sql\n\u2502       \u251c\u2500\u2500 fact_stock_latest.sql\n\u2502       \u2514\u2500\u2500 schema.yml\n\u251c\u2500\u2500 analyses/                   # Analyses SQL ad hoc\n\u251c\u2500\u2500 snapshots/                  # Historisation des donn\u00e9es\n\u251c\u2500\u2500 tests/                      # Tests unitaires et int\u00e9grit\u00e9\n\u251c\u2500\u2500 macros/                     # Fonctions SQL r\u00e9utilisables\n\u2514\u2500\u2500 seeds/                      # Tables statiques\n</code></pre>"},{"location":"terraform/","title":"Infrastructure Terraform \u2013 ShopNow Marketplace","text":"<p>Ce dossier contient les fichiers Terraform permettant de d\u00e9ployer l\u2019infrastructure cloud pour le DWH ShopNow, incluant :</p> <ul> <li>Resource Group Azure</li> <li>Event Hubs pour ingestion des flux</li> <li>Base de donn\u00e9es SQL Server / Azure SQL</li> <li>Stream Analytics pour transformation en temps r\u00e9el</li> <li>Conteneurs pour initialisation et producteurs d\u2019\u00e9v\u00e9nements (optionnel)</li> </ul>"},{"location":"terraform/#1-structure-du-projet-terraform","title":"1. Structure du projet Terraform","text":"<pre><code>terraform/\n\u251c\u2500\u2500 1_main.tf # D\u00e9ploiement principal\n\u251c\u2500\u2500 2_variables.tf # D\u00e9claration des variables\n\u251c\u2500\u2500 3_providers.tf # Providers Terraform (Azure)\n\u2514\u2500\u2500 modules/\n\u251c\u2500\u2500 container_producers/ # Module ACI pour producteurs\n\u251c\u2500\u2500 event_hubs/ # Module Event Hubs\n\u251c\u2500\u2500 make_docker_image/ # Module cr\u00e9ation image Docker\n\u251c\u2500\u2500 sql_database/ # Module SQL Server / DB\n\u2514\u2500\u2500 stream_analytics/ # Module ASA\n</code></pre>"},{"location":"terraform/#2-variables-terraform-2_variablestf","title":"2. Variables Terraform (<code>2_variables.tf</code>)","text":"Variable Type Description <code>username</code> string Nom utilisateur pour suffixes ressources <code>subscription_id</code> string ID de la subscription Azure <code>location</code> string R\u00e9gion Azure (ex : francecentral) <code>eventhubs</code> list(string) Liste des noms de Event Hubs (<code>orders</code>, <code>stock</code>, <code>clickstream</code>) <code>container_producers_image</code> string Image Docker pour les producteurs d\u2019\u00e9v\u00e9nements <code>sql_admin_login</code> string Login admin SQL <code>sql_admin_password</code> string, sensitive Mot de passe admin SQL <code>dockerhub_username</code> string Login DockerHub pour push/pull <code>dockerhub_token</code> string Token DockerHub <p>\ud83d\udca1 Conseil : Sensibles, ne pas commiter les credentials sur un repo public.</p>"},{"location":"terraform/#3-deploiement-principal-1_maintf","title":"3. D\u00e9ploiement principal (<code>1_main.tf</code>)","text":""},{"location":"terraform/#a-resource-group","title":"a. Resource Group","text":"<pre><code>resource \"azurerm_resource_group\" \"rg\" {\n  name     = \"rg-e6-${var.username}\"\n  location = var.location\n}\n</code></pre>"},{"location":"terraform/#b-event-hubs","title":"b. Event Hubs","text":"<ul> <li>Namespace Azure Event Hub (Basic SKU)</li> <li>Event Hubs : orders, stock, clickstream</li> <li>Autorisations send et listen</li> </ul>"},{"location":"terraform/#c-base-de-donnees-sql","title":"c. Base de donn\u00e9es SQL","text":"<ul> <li>Azure SQL Server + base dwh-shopnow</li> <li>Firewall : acc\u00e8s Azure et IP publique</li> <li>Backups court terme et long terme pour PITR / conformit\u00e9 RGPD</li> <li>Container optionnel pour ex\u00e9cution du script dwh_schema.sql lors de la cr\u00e9ation</li> </ul>"},{"location":"terraform/#d-stream-analytics","title":"d. Stream Analytics","text":"<ul> <li>Transformation des flux Event Hubs vers les tables fact :<ul> <li>fact_order / fact_order_items</li> <li>fact_clickstream</li> <li>fact_seller_product_stock</li> </ul> </li> <li>Entr\u00e9es : Event Hubs (orders, clickstream, stock)</li> <li>Sorties : Azure SQL Database</li> </ul>"},{"location":"terraform/#e-conteneurs-producteurs-optionnel","title":"e. Conteneurs Producteurs (optionnel)","text":"<ul> <li> <p>Azure Container Instance pour producteurs d\u2019\u00e9v\u00e9nements</p> </li> <li> <p>Variables d\u2019environnement : connexions Event Hub, SQL et intervalles de g\u00e9n\u00e9ration</p> </li> </ul>"},{"location":"terraform/#4-modules-terraform","title":"4. Modules Terraform","text":"Module Fonction event_hubs Cr\u00e9e namespace Event Hub + Hubs + policies sql_database Cr\u00e9e SQL Server, base et firewall stream_analytics Cr\u00e9e job ASA + inputs/outputs vers SQL make_docker_image Construit l\u2019image Docker pour producteurs container_producers D\u00e9ploie un ACI pour ex\u00e9cuter producers.py ## 5. Ex\u00e9cution Terraform <p>Copier les variables dans terraform.tfvars :</p> <pre><code>username                  = \"votre username\"\nsubscription_id           = \"votre azure subscription id\"\nlocation                  = \"francecentral\"\neventhubs                 = [\"orders\", \"products\", \"clickstream\", \"stock\"]\ncontainer_producers_image = \"sengsathit/event_hub_producers:latest\"\nsql_admin_login           = \"votre sql_admin_login\"\nsql_admin_password        = \"votre sql_admin_password\"\ndockerhub_username        = \"votre dockerhub_username\"\ndockerhub_token           = \"votre dockerhub_token\"\n</code></pre> <p>Initialiser Terraform : <pre><code>cd terraform\nterraform init\n</code></pre> V\u00e9rifier le plan : <pre><code>terraform plan\n</code></pre> Appliquer le plan : <pre><code>terraform apply\n</code></pre> Terraform cr\u00e9e automatiquement : - Resource Group - Event Hubs + namespace - SQL Server / Database - Stream Analytics Job avec inputs et outputs - Container pour l\u2019initialisation du sch\u00e9ma (si activ\u00e9) - Conteneur producteurs (si module d\u00e9comment\u00e9)</p>"}]}